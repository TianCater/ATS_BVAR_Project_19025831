---
# IMPORTANT: Change settings here, but DO NOT change the spacing.
# Remove comments and add values where applicable.
# The descriptions below should be self-explanatory

title: "Investigating the effects of ageing population on economic growth and healthcare expenditure for the US: A Bayesian-VAR"
#subtitle: "This will appear as Right Header"

documentclass: "elsarticle"

# --------- Thesis title (Optional - set to FALSE by default).
# You can move the details below around as you please.
Thesis_FP: FALSE
# Entry1: "An unbelievable study with a title spanning multiple lines."
# Entry2: "\\textbf{Nico Katzke}" # textbf for bold
# Entry3: "A thesis submitted toward the degree of Doctor of Philosophy"
# Uni_Logo: Tex/Logo.png # Place a logo in the indicated location (from your root, e.g. defaults to ~/Tex/Logo.png) and uncomment this line. Leave uncommented for no image
# Logo_width: 0.3 # If using a logo - use this to set width (size) of image
# Entry4: "Under the supervision of: \\vfill Prof. Joe Smith and Dr. Frank Smith"
# Entry5: "Stellenbosch University"
# Entry6: April 2020
# Entry7:
# Entry8:

# --------- Front Page
# Comment: ----- Follow this pattern for up to 5 authors
AddTitle: TRUE # Use FALSE when submitting to peer reviewed platform. This will remove author names.
Author1: "Tian Cater"  # First Author - note the thanks message displayed as an italic footnote of first page.
Ref1: "Advanced Time Series Econometrics 872 Project" # First Author's Affiliation
Email1: "19025831\\@sun.ac.za" # First Author's Email address

#Author2: "John Smith"
Ref2: "15 January 2023"
#Email2: "John\\@gmail.com"
#CommonAffiliation_12: TRUE # If Author 1 and 2 have a common affiliation. Works with _13, _23, etc.

#Author3: "John Doe"
#Email3: "Joe\\@gmail.com"

CorrespAuthor_1: FALSE  # If corresponding author is author 3, e.g., use CorrespAuthor_3: TRUE

# Comment out below to remove both. JEL Codes only given if keywords also given.
#keywords: "Multivariate GARCH \\sep Kalman Filter \\sep Copula" # Use \\sep to separate
#JELCodes: "L250 \\sep L100"

# ----- Manage headers and footers:
#BottomLFooter: $Title$
#BottomCFooter:
#TopLHeader: \leftmark # Adds section name at topleft. Remove comment to add it.
BottomRFooter: "\\footnotesize Page \\thepage" # Add a '#' before this line to remove footer.
addtoprule: TRUE
addfootrule: TRUE               # Use if footers added. Add '#' to remove line.

# --------- page margins:
margin: 2.3 # Sides
bottom: 2 # bottom
top: 2.5 # Top
HardSet_layout: TRUE # Hard-set the spacing of words in your document. This will stop LaTeX squashing text to fit on pages, e.g.
# This is done by hard-setting the spacing dimensions. Set to FALSE if you want LaTeX to optimize this for your paper.

# --------- Line numbers
linenumbers: FALSE # Used when submitting to journal

# ---------- References settings:
# You can download cls format here: https://www.zotero.org/ - simply search for your institution. You can also edit and save cls formats here: https://editor.citationstyles.org/about/
# Hit download, store it in Tex/ folder, and change reference below - easy.
bibliography: Tex/ref.bib       # Do not edit: Keep this naming convention and location.
csl: Tex/harvard-stellenbosch-university.csl # referencing format used.
# By default, the bibliography only displays the cited references. If you want to change this, you can comment out one of the following:
#nocite: '@*' # Add all items in bibliography, whether cited or not
# nocite: |  # add specific references that aren't cited
#  @grinold2000
#  @Someoneelse2010

# ---------- General:
RemovePreprintSubmittedTo: TRUE  # Removes the 'preprint submitted to...' at bottom of titlepage
Journal: "Journal of Finance"   # Journal that the paper will be submitting to, if RemovePreprintSubmittedTo is set to TRUE.
toc: FALSE                       # Add a table of contents
numbersections: TRUE             # Should sections (and thus figures and tables) be numbered?
fontsize: 11pt                  # Set fontsize
linestretch: 1.2                # Set distance between lines.
link-citations: TRUE            # This creates dynamic links to the papers in reference list.

### Adding additional latex packages:
header-includes:
   - \usepackage{graphicx} 
   - \usepackage{epstopdf} # Add additional packages here.
   - \usepackage{caption}
   - \usepackage{subcaption}
   - \usepackage[flushleft]{threeparttable}
   - \usepackage{threeparttablex}
   - \usepackage[export]{adjustbox}
   - \usepackage{bm}
   - \usepackage{amsmath}
   - \usepackage{enumitem}  

output:
  pdf_document:
    keep_tex: TRUE
    template: Tex/TexDefault.txt
    fig_width: 3.5 # Adjust default figure sizes. This can also be done in the chunks of the text.
    fig_height: 3.5
#abstract: |
---

<!-- First: Set your default preferences for chunk options: -->

<!-- If you want a chunk's code to be printed, set echo = TRUE. message = FALSE stops R printing ugly package loading details in your final paper too. I also suggest setting warning = FALSE and checking for warnings in R, else you might find ugly warnings in your paper. -->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, fig.width = 7, fig.height = 5.6, fig.pos="H", fig.align = "centre")
# Note: Include = FALSE implies the code is executed, but not printed in your pdf.
# warning and message = FALSE implies ugly messages and warnings are removed from your pdf.
# These should be picked up when you execute the command chunks (code sections below) in your rmd, not printed in your paper!

# Lets load in example data, and see how this can be stored and later called from your 'data' folder.
if(!require("tidyverse")) install.packages("tidyverse")
library(tidyverse)
Example_data <- Texevier::Ex_Dat

# Notice that as you are working in a .Rproj file (I am assuming you are) - the relative paths of your directories start at your specified root.
# This means that when working in a .Rproj file, you never need to use getwd() - it is assumed as your base root automatically.
write_rds(Example_data, path = "data/Example_data.rds")

pacman::p_load(BVAR, fredr, purrr, dplyr, writexl, tidyr, ggplot2, fmxdat, lubridate)

fred_api_key <- fredr_set_key("d3c88549b884b18ff71b2541742bd179")

fredr_has_key()

NGDP <- fredr(                         
  series_id = "A939RC0A052NBEA") |> dplyr::select(date, value) |>      
    filter(date >= lubridate::ymd("19600101")) |> 
    rename( NGDP = value)


HEX <- fredr(series_id = "G160271A027NBEA") |>     # Start date: 1959-01-01 # Is in Billions of dollars 
    dplyr::select(date, value) |>           # Notice is NOT logged
    filter(date >= lubridate::ymd("19600101")) |> 
        rename( HEX = value)


Population_total_thousands <- fredr(series_id = "B230RC0A052NBEA") |>    # Notice is in thousands  # Start date: 1929-01-01
    dplyr::select(date, value) |> 
    filter(date >= lubridate::ymd("19600101")) |> 
        rename( Pop_T_Th = value)


LIFEE <-  fredr(series_id = "SPDYNLE00INUSA") |>  # Life expectancy at birth indicates the number of years a newborn infant would live if prevailing patterns of mortality at the time of its birth were to stay the same throughout its life.
    dplyr::select(date, value) |>   # Start date: 1960-01-01
        rename( LIFEE = value)

    
Population_0_14 <- fredr(series_id = "SPPOP0014TOZSUSA") |>  # NOTE: The percent of total!
    filter(date >= lubridate::ymd("19600101")) |>  # Start date: 1960-01-01
    dplyr::select(date, value) |> 
        rename( Pop_0_14 = value)


Population_65_plus <- fredr(series_id = "SPPOP65UPTOZSUSA") |>  # NOTE: The percent of total!
    filter(date >= lubridate::ymd("19600101")) |>   # Start date: 1960-01-01
    dplyr::select(date, value) |> 
        rename( Pop_65_plus = value)

merged_data <- inner_join(NGDP, HEX, by = "date") |> inner_join(Population_total_thousands, by ="date") |> 
    inner_join(LIFEE, by ="date") |> inner_join(Population_0_14, by ="date") |> 
    inner_join(Population_65_plus, by ="date")

df <- merged_data |> mutate(HEX_pc = HEX*1000000/(Pop_T_Th)) |>  # Note: I transform HEX from billions and population from thousands, and take the HEX per capita
    mutate(AI = Pop_65_plus*100/Pop_0_14) |> 
    dplyr::select(date, NGDP, HEX_pc, LIFEE, AI) |> 
    
    rename("GDP" = NGDP, "HE" = HEX_pc, "LE" = LIFEE )


```


<!-- ############################## -->
<!-- # Start Writing here: -->
<!-- ############################## -->

# Introduction \label{Introduction}

Healthcare expenditure is positively correlated with economic growth. Specifically, the demand for healthcare services increases in response to economic growth.  [@fogel2004; @wang2011; @lopreite2017]. Over time, improved healthcare provisions increase life expectancy, requiring more healthcare financing to sustain the larger proportion of elderly individuals. In particular, the US has experienced a considerable shift in its demographic, a result of higher life expectancy combined with lower rates of fertility [@wiener2002;@linden2017; @williams2019]. As this disparity in demographics continues to widen, the increased healthcare costs will not be able to be offset by economic growth as the labour force starts to diminish relatively [@cheng2020]. 

To this end, this project aims to investigate the relationships between an ageing population, healthcare expenditure, life expectancy, and economic growth in the US empirically by applying Bayesian vector autoregression  (BVAR) techniques.

Impulse response analysis shows that the ageing population in the US not only negatively impacts economic growth but it also reverses the generally accepted relationship between health expenditure and economic growth; An increase in health expenditure exerts both short and long-run downward pressure on economic growth as the additional spending fails to generate more productivity.

Moreover, the findings show that, contrary to common belief, an increase in the gap between elderly and young individuals (the ageing index) causes persistent long-run reductions in life expectancy, indicating that the lower fertility rates have a more significant impact than the lower mortality rates amongst the elderly.    

The rest of this paper is structured as follows. Section \ref{lit} provides a brief review of the existing literature and underscores the contributions of this project. Section \ref{meth} presents the BVAR methodology and the subsequent priors used in estimating the model. Sections \ref{data} and \ref{stationarity} discuss the sample data and its stationarity, respectively. Lastly, Section \ref{est} specifies the selected prior distribution’s features and justification, provides the estimated results and conducts impulse response analysis and forecasting.  


# Literature Review \label{lit}

Various studies have investigated economic growth’s one-way relationship with healthcare expenditure. @murillo1993 shows that the variation in healthcare spending is significantly affected by GDP per capita for the nineteen OECD countries. On the other hand, @baltagi2010 also uses data from 1973 through 2006 for the twenty OECD countries and finds that relatively high healthcare expenditure is uncommon, even during abnormally high economic growth. @braendle2016 is another study where healthcare spending and income per capita are shown to be positively correlated. 

Furthermore, other literature investigates the bivariate causality between economic growth and expenditure. @wang2011, for example, finds that economic growth is promoted by healthcare spending between 1991 through 2010 using data on thirty-one countries. Complementarily, @amiri2012 shows for OECD countries that the two-way relationship between economic growth and healthcare expenditure maintains Granger causality. Also, using data from twenty OECD countries from 1981 through 2015, @amiri2016 shows that this bilateral association between healthcare spending and GDP is evident in more than three-quarters of the OECD countries considered. Studies also show that the reciprocal affiliation between these two variables is apparent in low-middle and high-income countries [@chaabouni2016 \& @halici2016]. 

The second widely investigated relationship in the literature is between healthcare spending, population ageing (or life expectancy), and economic growth. For example, @murthy2016 finds, using an ARDL model for data from 1958 to 2008 for the U.S., that advancements in healthcare technology, real income per capita,  and the proportion of the population over 65 are the leading causes of higher per capita healthcare spending. @jaba2014 used panel data for 110 nations between 1998 and 2012 and found that life expectancy and health spending are significantly positively correlated.  This positive relationship is iterated by @linden2017 for twenty-eight OECD countries for a sample period between 1985 and 2015.

 Estimating a BVAR model for Italy for 1992 to 2014, @lopreite2017 indicates that healthcare expenditure reacts less to economic growth than changes in the ageing index. @lopreite2020 also estimates a BVAR and compares the effect of an ageing population on health spending and GDP between China and the U.S. Their findings show that China’s ageing population is a much more dire concern for economic growth prospects compared to the U.S.  The mutual relationship between an ageing population and economic growth is driven by the age structure of the population, which impacts the speed at which economic growth is elicited, whereas this slower growth prospect, in turn, results in demographic changes (for example, @lee2000, @bloom2010, and @liotta2018)
 
This project contributes to the literature in at least two ways. First, in a similar fashion to @lopreite2020, I investigate the relationship between an ageing index, healthcare spending, economic growth, and life expectancy for the U.S. using a BVAR model. The Bayesian approach is specifically appropriate in this case as the sample is small (consisting of only annual data) and benefits from added predictive accuracy compared to the classic VAR model [@chan2017notes]. 

Second, I estimate and compare the BVAR model for both Minnesota prior and the conditional normal inverse-Wishart prior, incorporating prior beliefs on parameter distributions. ^[@lopreite2017 used a BVAR and compared the performance of the Minnesota and normal inverse-Wishart prior for Italy, whereas I use the conditional normal inverse-Wishart prior. ] Thus, the estimation enables comparing the short and medium-term impulse response analyses and forecasting performance for both adopted priors. 




# Methodology \label{meth}

I start by considering the following (reduced form) VAR(p) model with $\bm{y}_t = (y_{1t}, y_{2t}, ... , y_{nt})'$ represents a vector of dependent variables at time $t$: 

\begin{align}
\mathbf{y}_t = \bm{b} + \bm{A}_1 \bm{y}_{t-1} + ... + \bm{A}_p \bm{y}_{t-p} + \bm{\varepsilon}_t, \label{VAR} 
\end{align}

where $\bm{\varepsilon}_t \sim N(0, \bm{\Sigma})$ is the $n \times 1$ white noise error vector with covariance matrix $E(\bm{\varepsilon \varepsilon}')= \bm{\Sigma}$, $\bm{b}$ is a $n \times 1$ vector of intercepts, and $\bm{A}_1,.., \bm{A}_p$ is the  $n \times n$ coefficient matrices for the $p$ lags, respectively. That is, the VAR(p) model (\ref{VAR}) is a multiple equation regression with explained variables entering as the lagged explanatory variables. More generally, one can rewrite the VAR(p) as:

\begin{align}
\bm{y}_t = \bm{X}_t \bm{\beta}  + \bm{\varepsilon}_t, \label{VAR1}
\end{align}

where $\bm{X}_t = \bm{I}_n 	\otimes (1, \bm{y}'_{t-1}, ..., \bm{y}'_{t-p} )$ and $\bm{\beta} = vec([\bm{b}, \bm{A}_{1}, ..., \bm{A}_{p}])$. Then stack the observations over $t = 1,...,T$ to get:

\begin{align}
\bm{y} = \bm{X} \bm{\beta}  + \bm{\varepsilon}, \label{VAR2}
\end{align}

where $\bm{\varepsilon}  \sim N(0, \bm{I}_T \otimes \bm{\Sigma})$ and $\bm{X} = (\bm{X}_1, \bm{X}_2, ..., \bm{X}_T)'$ is a $Tn \times nk$ matrix. 

The goal of Bayesian methods is to obtain the posterior distribution that summaries all the information about the parameter vector given the data. That is, to estimate the parameters of the model ($\bm{\beta}$ and $\bm{\Sigma}$) one needs to apply Bayes rule:

\begin{align}
p(\bm{\beta}, \bm{\Sigma} | \bm{y}) &= \frac{p(\bm{y} | \bm{\beta}, \bm{\Sigma}) p( \bm{\beta}, \bm{\Sigma})}{p(\bm{y})} \\ 
 &\propto  p(\bm{y} | \bm{\beta}, \bm{\Sigma}) p( \bm{\beta}, \bm{\Sigma}),      \label{bayesrule}
\end{align}

where $p(\bm{\beta}, \bm{\Sigma} | \bm{y})$ is the joint posterior distribution , $p(\bm{y} | \bm{\beta}, \bm{\Sigma})$ the likelihood function, and  $p( \bm{\beta}, \bm{\Sigma})$ the joint prior distribution.

## The Minnesota Prior

The first BVAR estimation imposes the Minnesota or Litterman prior proposed by @litterman1986 and @doan1984. The reasons why I adopt the Minnesota prior are fourfold: firstly, the analysis uses three of the four series in levels, and the Minnesota prior’s robustness is optimal in this case; secondly, using the levels of the series, it is possible to analyse, through impulse response analyses and forecasts, the short and medium term dynamic relationships among the variables; thirdly, the estimated coefficients of the unrestricted VAR model is shrunk away from its OLS estimated and towards the prior mean by the Minnesota prior, thereby generating estimation gains. Lastly, the Minnesota prior has been shown to perform very well when considering smaller samples, as is the case here. 

The Minnesota prior is a shrinkage prior that holds $\bm{\Sigma}$ fixed to a data-based approximation for posterior sampling of $\bm{\beta}$, which simplifies prior elicitation and computation. That is, it replaces $\bm{\Sigma}$ with an estimate $\bm{\hat{\Sigma}}$, and assumes $\bm{\Sigma}$ is a diagonal matrix:

\begin{align}
\bm{\Sigma} = \begin{bmatrix} 
    \sigma^2_{1} & 0            & \dots  & 0 \\
    0            & \sigma^2_{2} & \dots  & 0 \\
    \vdots       &  \vdots            & \ddots & \vdots                 \\
    0            & 0        & \dots        & \sigma^2_{n} \\ 
    \end{bmatrix}
\end{align}

, with $\hat{\sigma^2_{ii}} = s^2_i$, the OLS estimate of the error variance in the $i$th equation. 

The Minnesota prior assumes, for $\bm{\alpha} = vec(\bm{\beta})$, that:

\begin{align}
\bm{\alpha} \sim N(\bar{\bm{\alpha}}, \bm{\Phi}_\alpha), 
\end{align}

where the prior mean of the coefficients $\bar{\bm{\alpha}}$ is a $kn \times 1$ vector of zeros, except for elements that relate to the first order own-lag terms. Let $i,j \in \{1,...,n\}$ where equations and variables are indexed by $i$ and $j$, respectively. Then, the construction of the prior variance matrix $\bm{\Phi}_\alpha$ for $\bm{\beta}$ can be specified for a general form of the decay function $d(l)$ as in @canova2007:
\begin{align}
 \bm{\Phi}_{\alpha(i,j)} (l) =
 \begin{cases} 
      \frac{V_1}{ d(l)} \\
      \frac{V_1 V_2 \sigma^2_j }{d(l) \sigma^2_i}  \label{hyper1} \\
      V_1 V_3 ,
\end{cases}
\end{align}

corresponding to own lags, cross variable lags, and exogenous variables respectively. 

The hyperparameters $V_1$, $V_2$, $V_3$, and $V_4$ govern the diagonal variance-covariance matrix. These hyperparameters has the following characteristics:
\begin{enumerate}[label=(\roman*)]
  \item $V_1$ dictates the comparative significance of the sample and prior information, indicating variance of the first lag’s overall tightness. Therefore, applying a modest value entails the prior dominating the sample information. On the other hand, the prior information becomes uninformative as $V_1$ tends to infinity and the estimates of the posterior converge towards the VAR coefficients. 
  \item $V_2$ establishes the comparative significance for the lags of variables on variables other than itself. 
The comparative significance of the information encompassed in the exogenous variables is controlled by $V_3$. 
  \item $V_4$ The decay function $d(l)$ is indexed by the hyperparameter $V_4 > 0$, where:
    \begin{itemize}
      \item if $d(l) = l^{V_4}$, then there is harmonic decay. 
      \item if $d(l) = V_4^{-l+1}$, the geometric decay,
      \item and if $V_1=1$, then linear decay. 
    \end{itemize}
\end{enumerate}

In this project, I use the specification by @koop2010 where $d(l) = l^2$ and the ratio of the variance of each equation has been inverted for the cross-equation coefficients, thereby setting the hyperparameter $V_4=2$:^[The selection and justification of the remaining hyperparameters is discussed later in section \ref{est} after the data and stationarity concerns have been analysed.]

\begin{align}
 \bm{\Phi}_{\alpha(i,j)} (l) =
 \begin{cases} 
      \frac{V_1}{ l^2} \\
      \frac{V_2 \sigma^2_i }{l^2 \sigma^2_j}  \label{hyper2} \\
      V_3 \sigma^2_{i}. 
\end{cases}
\end{align}

Finally, with $\bm{\Sigma}$ fixed, the posterior distribution of $\bm{\alpha} = vec(\bm{\beta})$ is given by:

\begin{align}
p(\bm{\alpha} | \bm{\Sigma}, \bm{X},\bm{y})  \propto  N[\bm{\Phi}_{\alpha}^{-1} + (\bm{\Sigma^{-1}} \otimes \bm{X}^T \bm{X}) \ , \bm{\Phi}_{\alpha}^{-1} \bar{\alpha} + vec(\bm{X}^T \bm{y} \bm{\Sigma}^{-1}) ] 
\end{align}




## The Conditional Normal Inverse-Wishart Prior



The priors take the following form

\begin{align}
p(\bm{\Sigma}) &\sim IW[\frac{1}{\bm{\gamma}} \bm{\Phi}_\sigma^{-1} , \bm(\gamma)], \\
p(\bm{\alpha} | \bm{\Sigma}) &\sim N[vec(\bm{\bar{\beta}}) , \bm{\Sigma} \otimes  \bm(\Phi)_\beta],
\end{align}

where the location matrix $\bm{\Phi}_\Sigma$ is formed in an identical way to the Minnesota prior; as the residual variance from equation-by-equation estimation of AR(p) models. The scaling of those parameters are governed by the hyperparameters $V_1$ and $V_3$, where:

\begin{align}
 \bm{\Phi}_{\beta(i,i)} (l) =
 \begin{cases} 
      \frac{V_1}{ l^2 \sigma^2_i} \\
      V_1 V_3 ,
\end{cases}
\end{align}

for lags and exogenous variables respectively. The conditional posterior distributions are given by:

\begin{align}
p(\bm{\Sigma}| \bm{X}, \bm{y}) \sim IW[\frac{\gamma}{\bm{\Phi}_\Sigma} + \bar{\bm{\beta}}^T \bm{\Phi}_\beta^{-1} \bar{\bm{\beta}} + \bm{y}^T \bm{y} - \tilde{\bm{\beta}}^T  \tilde{\bm{\Sigma}}_\beta^{-1} \bm{\beta}^2  \  , \ n - p + \bm{\gamma} ], \\
p(\bm{\alpha} | \bm{\Sigma}) \sim N[vec(\bm{\bar{\beta}}) , \bm{\Sigma} \otimes  \bm{\Phi}_\beta ],
\end{align}

where 
\begin{align}
\tilde{\bm{\Sigma}}_\beta^{-1} = \bm{\Phi}_\beta^{-1} + \bm{X}^T \bm{X},  \\
\tilde{\bm{\beta}} = \tilde{\bm{\Sigma}}_\beta (\bm{\Phi}_\beta^{-1} \bar{\bm{\beta}} + \bm{X}^T \bm{y} ). 
\end{align}

## The Gibbs Sampler

I then apply an Gibbs sampling algoritm for the VAR(p) to derive the posterior densities. The alorithm is as follows: Pick some initial values $\bm{\alpha}^{(0)} = \bm{c}_0$ and $\bm{\Sigma}^{(0)} = \bm{C}_0 > 0$, then repeat the following steps from $r =1$ to $R$ :

\begin{itemize}
 \item   Draw $\bm{\alpha}^{(r)} \sim p(\bm{\alpha}| \bm{X}, \bm{y}, \bm{\Sigma}^{(r-1)})$  (Multivariate Normal) 
 \item   Draw $\bm{\Sigma}^{(r)} \sim p(\bm{\Sigma}| \bm{X}, \bm{y}, \bm{\alpha}^{(r)})$    (Inverse-Wishart)
\end{itemize}

# The Data \label{data}

The data consists of annual U.S. data sampled over the period stretching from the start of 2016 to the end of 2020,  gathered from the Federal Reserve Bank of St. Louis' FRED database. The time series are plotted in Figure \ref{data} and consist of nominal Gross Domestic Product (GDP) per capita, healthcare expenditure per capita (HE), life expectancy at birth (LE), and a self-constructed ageing index (AI). ^[As will be evident in section \ref{stationarity}, nominal GDP growth per capita will be log difference to render it stationary, therby representing its annual growth.] 

Healthcare expenditure is the total government’s current expenditures on health (in Dollars), transformed to per capita terms using the age 16 and over civilian non-institutional population (HE). The ageing index (AI) is constructed similarly to @lopreite2017, as the logged ratio between the number of civilians aged 65 and over and the number of civilians aged 14 and less. The AI shows a persistent rise over time as the elderly population increases (numerator) while the young population decreases (denominator). Lastly, the life expectancy at birth (LE) series is defined as the average number of years a newborn is anticipated to live if, at the time of birth, the mortality rate remains constant throughout the newborn’s lifetime. 


```{r Visualising the data, warning=FALSE, fig.cap="Time series data sampled. \\label{data}"}

ts_plot <- df |> 
    
    rename("GDP: Nominal GDP per capita (Dollars)" = GDP, "HE: Healthcare expenditure per capita (Dollars)" = HE, "LE: Life Expectancy at birth (years)" = LE, "AI: Ageing index"= AI ) |> pivot_longer(cols = -date, names_to = "Variable", values_to = "Value") |> 
    
    ggplot() +
    
    geom_line(aes(date, Value, color = Variable), size = 1, alpha = 0.7) +
    
    annotate("rect", xmin = lubridate::ymd("20010301"), xmax = lubridate::ymd("20010901"), ymin = -Inf, ymax = Inf,alpha = .2, fill='steelblue', alpha= 0.05) +
    
     annotate("rect", xmin = lubridate::ymd("20071201"), xmax = lubridate::ymd("20090801"), ymin = -Inf, ymax = Inf,alpha = .2, fill='steelblue', alpha= 0.05) +
     annotate("rect", xmin = lubridate::ymd("20190101"), xmax = lubridate::ymd("20200101"), ymin = -Inf, ymax = Inf,alpha = .2, fill='steelblue', alpha= 0.05) +
    
    
    facet_wrap(~Variable, scales = "free_y") +
    
    
   fmxdat::theme_fmx(title.size = fmxdat::ggpts(30), 
                    subtitle.size = fmxdat::ggpts(0),
                    caption.size = fmxdat::ggpts(22),
                    CustomCaption = T, axis.size.title = ggpts(12), strip.size = ggpts(20), axis.size = ggpts(22)) + 
    
  fmxdat::fmx_cols() + 
  
  labs(x = "", y = "", caption = "Notes: The shaded areas reflect economic recessions as defined by the NBER and the COVID-19 pandemic from 2019. \nSource:  Federal Reserve Bank of St. Louis' FRED database; Bureau of Economic Analysis.",
       title = "",
       subtitle = "")
    
# And finally touches with finplot    

fmxdat::finplot(ts_plot, x.vert = T, x.date.type = "%Y", x.date.dist = "4 years", darkcol = T, legend_pos = "none")
    
    
```


# Stationarity  \label{stationarity}

To test the four variables for stationarity, I conduct the general-to-specific Augmented Dickey-Fuller (ADF) test approach [@dickey1979] . The approach entails testing hypothesis on three specifications of ADF test that have the following regressions with the corresponding test statistic and hypothesis:

i. Variable with trend and drift:
\begin{align}
\Delta y_t = b_0 +  \alpha y_{t-1}& + b_2 t + \sum_{j=2}^{p} \beta_j \Delta y_{t-j +1} + \varepsilon_t \label{adf1} \\
H_0 : \alpha =0& \ \& \ b_0=0 \ \& \ b_2 = 0 \ (test \ statistic = \phi_2) \notag \\
H_0 : \alpha =0& \ \& \ b_0=0  \ (test \ statistic = \phi_3) \notag \\
H_0 : \alpha =0& \ (test \ statistic = \tau_3) \notag
\end{align}
ii. Variable with drift and no trend: 
\begin{align}
\Delta y_t = b_0 +  \alpha y_{t-1}& + \sum_{j=2}^{p} \beta_j \Delta y_{t-j +1} + \varepsilon_t  \label{adf2} \\
H_0 : \alpha =0& \ \& \ b_0=0  \ (test \ statistic = \phi_1) \notag \\
H_0 : \alpha =0& \ (test \ statistic = \tau_2) \notag
\end{align}
iii. Variable with no drift or trend:
\begin{align}
\Delta y_t =  \alpha y_{t-1}& + \sum_{j=2}^{p} \beta_j \Delta y_{t-j +1} + \varepsilon_t  \label{adf3} \\
H_0 : \alpha =0& \ (test \ statistic = \tau_1) \notag
\end{align}
One or more test statistics are attached to each regression above, testing restrictions on the parameters of interest. The corresponding test statistics differ depending on the different specifications of each equation. In short, $\tau =0$  suggests the existence of a unit root, $\phi_1=0$ or $\phi_3=0$  indicates no intercept and a unit root, and $\phi_2=0$ no intercept nor trend and a unit root for each of the four variables. The test statistics and their corresponding critical values are provided in Table \ref{steady} for each variable.^[The null hypothesis under each specification is rejected at the corresponding significance level if the absolute value of the test statistic is larger than the absolute value of the critical value. I.e. Reject the null i.f.f. $|test \ stat.| > |critical value|$.]

\begin{small}
\begin{longtable}{|llll|||llll|}
\caption{General-to-specific ADF tests for $p=3$. \label{steady}}\\%
\hline%
\multicolumn{1}{|l}{\textbf{Test Statistic}} &
\multicolumn{1}{l}{\textbf{CV: 1\%}} &
\multicolumn{1}{l}{\textbf{5\%}} &
\multicolumn{1}{l}{\textbf{10\%}}&
\multicolumn{1}{l}{\textbf{Test Statistic}} &
\multicolumn{1}{l}{\textbf{CV: 1\%}} &
\multicolumn{1}{l}{\textbf{5\%}} &
\multicolumn{1}{l|}{\textbf{10\%}}\\%
\hline\hline%
\endfirsthead
\multicolumn{4}{l}{{\tablename} \thetable{} -- Continued}\\%
\hline%
\hline%
\multicolumn{1}{|l}{\textbf{Test Statistic}} &
\multicolumn{1}{l}{\textbf{CV: 1\%}} &
\multicolumn{1}{l}{\textbf{5\%}} &
\multicolumn{1}{l}{\textbf{10\%}}&
\multicolumn{1}{l}{\textbf{Test Statistic}} &
\multicolumn{1}{l}{\textbf{CV: 1\%}} &
\multicolumn{1}{l}{\textbf{5\%}} &
\multicolumn{1}{l|}{\textbf{10\%}}\\%
\hline\hline%
\endhead
 \multicolumn{4}{|c|||}{$\textbf{GDP} \ (growth \ per \ capita)$} &  \multicolumn{4}{c|}{$\textbf{HE}$} \\
\hline
\multicolumn{8}{|c|}{Level variable with trend and drift}\\
\hline
  $\tau_3$ = -5.23  &  -4.04   & -3.45   & -3.15  &  $\tau_3$ = 2.04 &  -4.04   & -3.45   & -3.15  \\
  $\phi_2$ = 6.2    &   6.5    & 4.88    &  4.16  &  $\phi_2$ = 3.17 &   6.5    & 4.88    &  4.16  \\
  $\phi_3$ = 14.33   &   8.73   & 6.49    &  5.74  &  $\phi_3$ = 4.6 &   8.73   & 6.49    &  5.74 \\
\hline
  \multicolumn{8}{|c|}{Level variable with drift and no trend}\\
\hline
  $\tau_2$ = -3.41 & -3.51  & -2.89  & -2.58   & $\tau_2$ = 3.05 & -3.51  & -2.89  & -2.58 \\
  $\phi_1$ = 8.7 &    6.7       & 4.71     & 3.86      &   $\phi_1$ = 4.8 &    6.7       & 4.71     & 3.86  \\
\hline
  \multicolumn{8}{|c|}{Level variable with no drift and no trend}\\
\hline
  $\tau_1$ = -2.195  & -2.60  & -1.95 & -1.61 & $\tau_1$ = 3.1 & -2.60  & -1.95 & -1.61    \\
\hline
 \multicolumn{4}{|c|||}{$\textbf{LE}$} &  \multicolumn{4}{c|}{$\textbf{AI} \ (logged)$} \\
\hline
\multicolumn{8}{|c|}{Level variable with trend and drift}\\
\hline
  $\tau_3$ = 0.97 &  -4.04   & -3.45   & -3.15 & $\tau_3$ = -6.77  &  -4.04   & -3.45   & -3.15 \\
  $\phi_2$ = 3.93 &   6.5    & 4.88    &  4.16  & $\phi_2$ = 16.36 &   6.5    & 4.88    &  4.16    \\
  $\phi_3$ = 2.15     &   8.73   & 6.49    &  5.74  &  $\phi_3$ = 22.94  &   8.73   & 6.49    &  5.74   \\
\hline
  \multicolumn{8}{|c|}{Level variable with drift and no trend}\\
\hline
  $\tau_2$ = -1.65 & -3.51  & -2.89  & -2.58  & $\tau_2$ = -1.6 & -3.51  & -2.89  & -2.58  \\
  $\phi_1$ = 5.07 &    6.7       & 4.71     & 3.86  & $\phi_1$ =  2.2  &    6.7       & 4.71     & 3.86  \\
\hline
  \multicolumn{8}{|c|}{Level variable with no drift and no trend}\\
\hline
  $\tau_1$ = 2.59 & -2.60  & -1.95 & -1.61  & $\tau_1$ = 1.15 & -2.60  & -1.95 & -1.61   \\
\hline%
\end{longtable}
\end{small}

The number of lags for each variable set to 3 according to the Akaike information criterion (AIC) and Bayesian information criterion (BIC). Upon initially running the ADF tests on nominal GDP per capita, the presence of a unit root for all three specifications (\ref{adf1}), (\ref{adf2}), and (\ref{adf3}). However, nominal GDP growth per capita (by log differencing) is stationary when including a drift term. This can be seen in Table \ref{steady}; The null hypothesis of no trend, no drift, and the presence of a unit root cannot be rejected at the $1 \%$ significance level ($|\phi_2| < |CV_{1\%}|$). However, the null hypothesis of no drift and the presence of a unit root can be rejected at the 1% significance level ($|\phi_3| > |CV_{1\%}|$). This is verified by the same reasoning when hypothesising using $\phi_1$  and $\tau_2$.  

The results of the ADF tests is the same for both healthcare expenditure (HE) and life expectancy at birth (LE); The null hypothesis of no trend, no drift, and the presence of a unit root cannot be rejected at all significance levels. However, when considering the specification in equation (\ref{adf2}), then the hypothesis of no drift and a unit root is rejected at the $5\%$ significance level. Therefore, an AR(3) with drift for both HE and LE are stationary. Under the same reasoning, the (logged) ageing index (AI) is stationary when including drift and and trend.  

 
 
 
# Results: Estimation, Impulse Responses, and Forecast Analysis \label{est}

The estimated BVAR's number of lags are set to 3 according to the AIC and BIC and a constant term is included in the model following the stationarity tests conducted in previous section \ref{stationarity}. I choose the four covariance matrix hyperparameters of the Minnesota prior (shown in equations \ref{hyper1} and \ref{hyper2}) in the following fashion: $V_1$, reflecting the importance of prior beliefs,  is set to a comparatively minor value as the prior information affect the estimation regarding the information contributed by the data; $V_2$ (lags across variables) and $V_3$ (exogenous variables) is set to larger than zero as, for this analysis, the estimates of the cross variable lags and the exogenous variables is central. The ‘lag decay’ hyperparameter $V_4$ is set to two similar to @koop2010, thereby adopting a harmonic decay structure.  

The  posterior distributions of the coefficients for the Minnesota and conditional normal inverse-Wishart priors are shown in Figures \ref{posterior_minnesota} and \ref{posterior_iw} in \ref{aa}, respectively. This section proceeds by analysing and comparing the impulse response functions and forecasts under both priors.

## Impulse Response Functions

The percentage-point response to a one standard deviation shock for each variable on each other for the Minnesota and conditional inverse-Wishart prior is depicted in Figures \ref{irf_minnesota} and \ref{irf_iw}, respectively. In the case of responses from GDP (growth) and HE, the responses are given as the percentage point times 100.

In the case of the Minnesota prior (Figure \ref{irf_minnesota}),  a HE shock decreases the GDP growth rate by approximately 1.3$\%$ over 3 years, increasing back after 5 years and then marginally increasing it past pre-shock levels. Importantly, a shock from AI reduces GDP growth by approximately 0.8$\%$ over 2 years, returning to its pre-shock levels a year later. The shock from HE on AI shows that the additional expenditure on healthcare only starts to increase AI after 4 years. In addition, a shock on HE has a persistent and negative effect on LE, showing that healthcare expenditure is implemented in a more reactive than proactive way. For example, during the COVID-19 pandemic, the increase in HE was in response to LE persistently declining. The shock from LE to HE, in turn, shows that as the LE starts to increase, there is a gradual and persistent reduction in HE.

Another interesting observation is that a shock from AI has a negative and persistent long-run effect on LE. This shows that the increase in the ageing index (AI) is more dependent on higher mortality for individuals aged 14 or less than lower mortality for ages 65 and over, causing the persistent reduction in LE. The corresponding shock on LE positively impacts GDP growth; however, the wide error bands show that this observation is not robust. 

Compared to the impulse responses when the conditional inverse-Wishart prior was adopted (Figure \ref{irf_iw}), the observations are generally the same with a few differences. Specifically, a shock from HE has an insignificant effect on AI. However,  the negative impact of HE on LE is amplified compared to the responses under the Minnesota prior, further exacerbating the reactiveness, as opposed to the proactiveness,  of HE to LE.


\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{irf_minnesota.eps}
  \caption{Minnesota prior: Impulse responses. Each plot shows the percentage-point response of the indicated variable from its steady state to a one-standard-deviation indicated shock when the Minnesota prior was adopted. Periods are in years. In the case of responses from GDP (growth) and HE, the responses are given as the percentage point times 100.}
  \label{irf_minnesota}
\end{figure}


\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{irf_iw.eps}
  \caption{Conditional normal inverse-Wishart prior: Impulse responses. Each plot shows the percentage-point response of the indicated variable from its steady state to a one-standard-deviation indicated shock when the Conditional normal inverse-Wishart  prior was adopted. Periods are in years. In the case of responses from GDP (growth) and HE, the responses are given as the percentage point times 100. }
  \label{irf_iw}
\end{figure}



## Forecasts

The 20-year forecasts for the four variables under the adopted Minnesota and conditional inverse-Wishart priors are shown in Figures \ref{for_minnesota} and \ref{for_iw}, respectively. Due to the similarities across Figures, I only analyse the case for the Minnesota prior.

The projections show a persistent increase in the ageing index (AI) and a continued decrease in life expectancy at birth (LE). This matches my recent experience in the US and again highlights the source of the reduced AI; the increased mortality of individuals aged 14 and younger is larger than the lowered mortality for individuals aged 65 and over, thereby reducing LE whilst increasing AI.  As indicated in the impulse response analysis, healthcare expenditure persistently increases due to the lowered life expectancy. 


\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{Forecast_minnesota.eps}
  \caption{Minnesota prior: Estimated forecasts. Periods are in years.}
  \label{for_minnesota}
\end{figure}


\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{Forecast.eps}
  \caption{Conditional normal inverse-Wishart prior: Estimated forecasts. Periods are in years.}
  \label{for_iw}
\end{figure}



# References {-}

<div id="refs"></div>

\newpage
\appendix
\renewcommand{\thesection}{Appendix A}

#  \label{aa}

\begin{figure}
     \centering
     \begin{subfigure}[H]{0.49\textwidth}
         \centering
         \includegraphics[width=\textwidth]{minn_Constant.eps}
     \end{subfigure}
     \begin{subfigure}[H]{0.49\textwidth}
         \centering
         \includegraphics[width=\textwidth]{minn_CoefLag1.eps}
     \end{subfigure}
    \begin{subfigure}[H]{0.49\textwidth}
         \centering
         \includegraphics[width=\textwidth]{minn_CoefLag2.eps}
     \end{subfigure}
    \begin{subfigure}[H]{0.49\textwidth}
         \centering
         \includegraphics[width=\textwidth]{minn_CoefLag3.eps}
    \end{subfigure}
        \caption{Minnesota prior: Estimated BVAR(3) coefficients' posterior distributions using Gibbs sampling.}
        \label{posterior_minnesota}
\end{figure}


\begin{figure}
     \centering
     \begin{subfigure}[H]{0.49\textwidth}
         \centering
         \includegraphics[width=\textwidth]{Constant.eps}
     \end{subfigure}
     \begin{subfigure}[H]{0.49\textwidth}
         \centering
         \includegraphics[width=\textwidth]{CoefLag1.eps}
     \end{subfigure}
    \begin{subfigure}[H]{0.49\textwidth}
         \centering
         \includegraphics[width=\textwidth]{CoefLag2.eps}
     \end{subfigure}
    \begin{subfigure}[H]{0.49\textwidth}
         \centering
         \includegraphics[width=\textwidth]{CoefLag3.eps}
    \end{subfigure}
        \caption{Conditional normal Inverse-Wishart prior: Estimated BVAR(3) coefficients' posterior distributions using Gibbs sampling.}
        \label{posterior_iw}
\end{figure}